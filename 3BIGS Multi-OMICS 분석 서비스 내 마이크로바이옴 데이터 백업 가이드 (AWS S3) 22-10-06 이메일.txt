[3BIGS] Multi-OMICS 분석 서비스 내 마이크로바이옴 데이터 백업 가이드 (AWS S3) 22-10-06
받은편지함

이현배 <hblee@3bigs.com>
첨부파일
10월 6일 (목) 오후 1:15
나, 김광민, Sathishkumar, 정호용, 박준형에게

박보현 주임연구원님 안녕하세요,

(주)쓰리빅스 이현배 매니저입니다.

쓰리빅스가 제공하고 있는 NGS기반 분석 서비스 내 마이크로바이옴 분석 데이터는 박보현 주임님이 관리하고 있으며,
모든 데이터는 쓰리빅스 사무실에 위치하고 있는 OMICSBOX PC에 보관하고 있는점 확인하였습니다.

현재 파악된 백업 데이터는 2019년부터 최근까지 발생된 분석건에 대한 데이터로 그 크기는 약 2.2TB 입니다.
물리적으로 제한된 하드디스크 공간으로 인해, 추후 모든 데이터 백업은 AWS S3로 진행하고자 합니다.

이에 OMICSBOX PC에 저장되어 있는 데이터와 앞으로 있을 데이터는 아래 내용을 참고하여 S3로 백업하여 주시기 바랍니다. (2019, 2020 포함 전체)
- 3bigsmicrobiome bucket 내 폴더 생성 및 관리는 주임님 재량으로 진행

1. AWS 계정 안내 
마이크로바이옴 데이터 백업을 위해 별도의 계정을 생성하였습니다. 해당 계정은 Web 또는 AWS CLI에서 접근 가능합니다.
단, AWS내 S3, 중 특정 Bucket만 접속하여 데이터 업로드, 다운로드만 가능하도록 권한 설정하였기 때문에 EC2, EFS 등 다른 서비스를 이용할 수 없습니다.

1.1 웹페이지를 통한 접근방법

접속 주소 : https://007710480879.signin.aws.amazon.com/console
(일반 AWS 사이트에서도 아래 계정을 통해 접속 가능)

account (12자리) : 007710480879
ID : 3bigs_omicsdata
PW : 3bigs!@#$

오직 S3 3bigsmicrobiome bucket만 접근 가능함
웹을 통해 폴더를 생성하거나 Drag & Drop 하여 업로드, 다운로드 및 삭제 할 수 있습니다.
이는 간단한 작업을 할 때 활용할 수 있지만, 리눅스 환경에선 적합하지 않습니다.

* 로그인 화면
image.png
* 로그인 후 콘솔 홈
image.png

* S3 서비스 내 화면 (권한 부족으로 뜸)
image.png

* 권한이 없는 다른 bucket
image.png

권한이 있는 3bigsmicrobiome bucket
image.png


1.2 AWS CLI를 통한 접근방법

아래 링크를 통해 각 운영체제에 맞게 프로그램을 설치한 후 계정에 맞는 ID 및 Secret key를 설정하면 S3에 접근 가능합니다.
https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/getting-started-install.html
KT서버에 리눅스버전, OMICSBOX PC버전을 각각 설치하고 계정을 등록하여 주시기 바랍니다.


AWS CLI 설치 후 계정 설정 방법

설치 확인
> aws --version

계정 설정
> aws configure

AWS Access Key ID : AKIAQDS4UTHXYNTWSNDZ
AWS Secret Access Key : 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
Default region name : 
Default output format :

(첨부파일 참고, 계정정보 분실시 신규 발급 가능)

image.png

2. AWS CLI를 이용한 데이터 복사 및 안내

AWS CLI는 S3 뿐만 아니라 EC2, EFS 등 다양한 서비스를 접근하고 제어할 수 있습니다. 그러나 부여한 계정에서는 S3만 이용 가능하며
간단한 명령어를 통해 대용량 데이터를 일괄 복사, 삭제가 가능합니다.
이 때, 활성화 되어 있는 창을 닫게 될 경우, 명령어도 종료되니 리눅스에선 screen 사용을 권장합니다.

참고 : https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/cli-configure-options.html

기본적인 명령어는 다음과 같습니다 :

ls : 리스트 보기
cp : 복사하기
mv : 옮기기
rm : 제거하기

옵션 : --recursive (현재 위치에 있는 모든 파일 일괄)

명령어 입력은 기본적으로 리눅스와 동일합니다.
aws s3 [명령어] [복사할 파일 또는 폴더] [복사될 위치] 

ex) Local의 특정 파일을 S3 3bigsmicrobiome bucket에 복사하기
> aws s3 cp [파일이 있는 위치 및 파일명] s3://3bigsmicrobiome/

ex) Local의 특정 폴더내 파일 전체를 S3 3bigsmicrobiome bucket에 복사하기
> aws s3 cp [폴더가 있는 위치 및 폴더내] s3://3bigsmicrobiome/ --recursive

ex) Local의 특정 폴더내 파일 전체를 S3 3bigsmicrobiome bucket 내 신규 폴더를 생성하여 복사하기
> aws s3 cp [폴더가 있는 위치 및 폴더내] s3://3bigsmicrobiome/[신규 폴더명]/ --recursive

ex) S3 3bigsmicrobiome bucket 내 폴더 또는 파일을 local에 일괄 복사하기
> aws s3 cp s3://3bigsmicrobiome/[폴더가 있는 위치 또는 파일]/ [local위치] --recursive

image.png

기타 궁금하신 점 있으시면 연락 바랍니다.

감사합니다.

이현배 드림

################################################################################################################################################

박보현 <bhpark@3bigs.com>
10월 7일 (금) 오후 2:52
이현배, 김광민, Sathishkumar, 정호용, 박준형에게

이현배 매니저님, 안녕하세요.

BDG 박보현 주임연구원입니다.

마이크로바이옴 데이터 백업을 위한 AWS S3 가이드라인을 상세히 전달해주셔서 매우 감사드립니다 :)

KT 서버 메모리 및 Omicsbox PC 드라이브 메모리 이슈로 인하여, 데이터 분석을 위한 서버 공간 확보가 어려웠었습니다.

하지만 공유해주신 내용을 토대로 AWS S3에 microbiome 분석 데이터 백업이 가능한 점을 파악하였습니다.

앞으로 AWS S3를 활용하여 microbiome 분석 데이터를 관리한다면, 서버 메모리 이슈 등은 없지 않을까 생각이 듭니다.

현재는 급한 분석을 위해 임시로 S3 내에 폴더를 생성하여 일부 데이터를 백업하여 사용하고 있습니다.

추후 급한 업무를 마무리하여 시간적 여유가 될 때, KT 서버 및 Omicsbox PC 내에 있는 모든 마이크로바이옴 데이터를 일정 기준을 세워 AWS S3에 백업하여 관리하도록 하겠습니다.

감사합니다.

박보현 드림

################################################################################################################################################

박보현 <bhpark@3bigs.com>
첨부파일
오후 1:47 (1시간 전)
이현배, 김광민, Sathishkumar, 정호용, 박준형에게

이현배 매니저님, 안녕하세요.

BDG 박보현 주임연구원입니다.

마이크로바이옴 데이터 백업 관련하여 내용 전달 드립니다.

이전까지 마이크로바이옴 서비스 데이터는 OMICSBOX PC server_2 F 드라이브 내의 Metagenome_backup 폴더에 관리하고 있었습니다.

하지만 분석 서비스가 늘어남에 따라 하드디스크 메모리 용량이 부족하여, 데이터 저장 및 보관에 이슈가 있었습니다.

지난 달 매니저님께서 AWS S3 3bigsmicrobiome bucket 생성 및 백업 가이드를 전달 주셨고, 현재 1차적으로 데이터 백업을 진행 완료하였습니다.

OMICSBOX PC F: Metagenome_backup 폴더에는 KT 서버 4개 각각에 대한 백업 폴더가 있었는데, 관련 데이터를 모두 AWS S3로 백업하였습니다.
- Metagenome_backup/KT_microbiome_server_backup
- Metagenome_backup/KT_microbiome2_server_backup
- Metagenome_backup/KT_qiime2_server_backup
- Metagenome_backup/KT_qiime2v2_server_backup

3bigsmicrobiome bucket은 분석 연도별로 폴더를 생성하였고, 각 연도에 분석한 서비스에 대하여 프로젝트 별로 폴더를 생성하여 백업하였습니다.

image.png

프로젝트 아이디를 부여받지 못한 연구용 분석이나 내부 논문용 분석 등은 분석한 날짜로 폴더를 생성하였습니다.

관련하여 아래 엑셀 파일로 정리하였으니, 참고부탁드립니다.

추후 시간적 여유가 있을 때, 계속해서 데이터 백업 및 분석 결과 백업도 진행할 예정입니다.

감사합니다.

박보현 드림

################################################################################################################################################

이현배
오후 2:09 (1시간 전)
나, 김광민, Sathishkumar, 정호용, 박준형에게

박보현 주임님 안녕하세요,

기획전략팀 이현배 매니저입니다.

백업내용을 정리해주셔서 감사합니다. 프로젝트명으로 분류되어 있어 고객응대하면서 관련 자료를 찾을 때, 제가 직접 쉽게 찾을 수 있어 좋네요.

백업된 데이터는 90일, 180일 기준으로 Storage class를 분리하여 관리하게 됩니다. (비용절감 측면)
90일 이후에는 보관된 데이터를 불러오고 다운받는데, 하루에서 이틀정도 소요될 수 있으니 참고하여 주시기 바랍니다.

image.png

추후에 F드라이브에 남아있는 이전 데이터도 S3로 이전하여 주시기 바랍니다.
이번주 목요일에 예정되어 있는 OMICSBOX PC 백업과정에서 해당 백업 폴더는 그대로 두도록 하겠습니다.

감사합니다.

이현배 드림

################################################################################################################################################


박보현 <bhpark@3bigs.com>
첨부파일
오후 3:19 (2분 전)
이현배, 김광민, Sathishkumar, 정호용, 박준형에게

이현배 매니저님, 안녕하세요.

BDG 박보현 주임연구원입니다.

AWS S3 백업 데이터에 대한 storage class 내용을 잘 확인하였습니다, 내용 전달해주셔서 감사드립니다.

추가로 OMICSBOX PC F 드라이브의 Metagenome_backup/2019_Metagenome/ 폴더를 AWS S3로 백업 하였습니다. (3bigsmicrobiome/Analysis_2019/)

image.png


업데이트된 엑셀 파일 첨부드렸으니, 참고 부탁드립니다.

그리고 목요일에 OMICSBOX PC 백업하실 때, Metagenome_backup 폴더는 백업하지 않으셔도 될 것 같습니다.

F 드라이브의 용량은 사용가능 용량을 0 byte -> 1.77TB로 확보해두었습니다.

image.png


감사합니다.

박보현 드림

하위 내용 추가
